{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Samer AlTaki\n",
    "### IOT & Computer Vision \n",
    "## Task1 :\n",
    "### 1.1 Object Detector In Image\n",
    "### 1.2 Object Detector In Vedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Object Detector In Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('examples/test-image.jpg')\n",
    "image = cv2.resize(image, (640, 480))\n",
    "h = image.shape[0]\n",
    "w = image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to the weights and model files\n",
    "weightsPath = \"ssd_mobilenet/frozen_inference_graph.pb\"\n",
    "configPath = \"ssd_mobilenet/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "\n",
    "# load the MobileNet SSD model\n",
    "net = cv2.dnn.readNetFromTensorflow(weightsPath,configPath)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'] 90\n"
     ]
    }
   ],
   "source": [
    "# load the class labels\n",
    "class_names = []\n",
    "with open(\"ssd_mobilenet/coco_names.txt\", \"r\") as f:\n",
    "    class_names = f.read().strip().split(\"\\n\")\n",
    "print(  class_names, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blob from the image\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0/127.5, (320, 320), [127.5, 127.5, 127.5])\n",
    "# pass the blog through our network and get the output predictions\n",
    "net.setInput(blob)\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over the number of detected objects\n",
    "for detection in output[0, 0, :, :]:\n",
    "    probability = detection[2]\n",
    "    if probability < 0.5:\n",
    "        continue\n",
    "\n",
    "        \n",
    "    # perform element-wise multiplication to get the (x, y) coordinates of the bounding box        \n",
    "    box = [int(a * b) for a, b in zip(detection[3:7], [w, h, w, h])]\n",
    "    box = tuple(box)\n",
    "    \n",
    "    \n",
    "    # draw the bounding box of the object    \n",
    "    cv2.rectangle(image, box[:2], box[2:], (0, 255, 0), thickness=2)\n",
    "    \n",
    "    # draw the name of the predicted object along with the probability\n",
    "    class_id = int(detection[1])\n",
    "    label = f\"{class_names[class_id - 1].upper()} {probability * 100:.2f}%\"\n",
    "    cv2.putText(image, label, (box[0], box[1] + 15),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Object Detector In Vedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(\"examples/test-video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the width and the height of the video stream\n",
    "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the FourCC and a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "writer = cv2.VideoWriter(\"output.mp4\", fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# path to the weights and model files\n",
    "weights1 = \"ssd_mobilenet/frozen_inference_graph.pb\"\n",
    "model1 = \"ssd_mobilenet/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\"\n",
    "# load the MobileNet SSD model trained  on the COCO dataset\n",
    "net1 = cv2.dnn.readNetFromTensorflow(weights1, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names1 = []\n",
    "with open(\"ssd_mobilenet/coco_names.txt\", \"r\") as f:\n",
    "    class_names1 = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of random colors to represent each class\n",
    "np.random.seed(42)\n",
    "colors1 = np.random.randint(0, 255, size=(len(class_names1), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the frames\n",
    "while True:\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    success, frame = video_cap.read()\n",
    "    h1 = frame.shape[0]\n",
    "    w1 = frame.shape[1]\n",
    "\n",
    "    # create a blob from the frame\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0/127.5, (320, 320), [127.5, 127.5, 127.5])\n",
    "    \n",
    "    # pass the blog through our network and get the output predictions\n",
    "    net1.setInput(blob)\n",
    "    output1 = net1.forward() # shape: (1, 1, 100, 7)\n",
    "\n",
    "    # loop over the number of detected objects\n",
    "    for detection in output1[0, 0, :, :]: \n",
    "        probability1 = detection[2]\n",
    "        if probability1 < 0.5:\n",
    "            continue\n",
    "\n",
    "        # extract the ID of the detected object\n",
    "        class_id1 = int(detection[1])\n",
    "        label1 = class_names1[class_id1 - 1].upper()\n",
    "        color1 = colors1[class_id1]\n",
    "        B, G, R = int(color1[0]), int(color1[1]), int(color1[2])\n",
    "        # perform element-wise multiplication to get the (x, y) coordinates of the bounding box\n",
    "        box1 = [int(a * b) for a, b in zip(detection[3:7], [w1, h1, w1, h1])]\n",
    "        box1 = tuple(box1)\n",
    "        # draw the bounding box of the object\n",
    "        cv2.rectangle(frame, box1[:2], box1[2:], (B, G, R), thickness=2)\n",
    "\n",
    "        # draw the name of the predicted object along with the probability\n",
    "        text1 = f\"{label1} {probability1 * 100:.2f}%\"\n",
    "        cv2.putText(frame, text1, (box1[0], box1[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # end time to compute the fps\n",
    "    end = datetime.datetime.now()\n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50),cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    # write the frame to disk\n",
    "    writer.write(frame)\n",
    "    if cv2.waitKey(10) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# release the video capture, video writer, and close all windows\n",
    "video_cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
